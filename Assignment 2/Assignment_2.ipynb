{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk scikit-learn gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIicrBwUw51D",
        "outputId": "3d6e902b-a01a-48a9-a293-90164c3254e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "ycRe6D9lw9we"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f4CD_HaxBxa",
        "outputId": "65970290-360e-4211-c5e3-1ab51532d67d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"I love machine learning\",\n",
        "    \"Machine learning is amazing\",\n",
        "    \"I love AI and data science\",\n",
        "    \"Data science uses machine learning\"\n",
        "]"
      ],
      "metadata": {
        "id": "cg80Sze8xHWX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "processed_docs = []\n",
        "\n",
        "for doc in documents:\n",
        "    tokens = word_tokenize(doc.lower())\n",
        "    filtered = [w for w in tokens if w.isalpha() and w not in stop_words]\n",
        "    processed_docs.append(\" \".join(filtered))\n",
        "\n",
        "print(processed_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tASfK3PWxDQ1",
        "outputId": "7c560da0-0a84-4186-e0af-7f1bcfcfd310"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['love machine learning', 'machine learning amazing', 'love ai data science', 'data science uses machine learning']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "bow_matrix = count_vectorizer.fit_transform(processed_docs)\n",
        "\n",
        "print(\"Vocabulary:\", count_vectorizer.get_feature_names_out())\n",
        "print(\"\\nBoW Matrix:\\n\", bow_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r4iJWL_ysqv",
        "outputId": "68bc7503-e773-4c09-e067-dffefb6eabe2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['ai' 'amazing' 'data' 'learning' 'love' 'machine' 'science' 'uses']\n",
            "\n",
            "BoW Matrix:\n",
            " [[0 0 0 1 1 1 0 0]\n",
            " [0 1 0 1 0 1 0 0]\n",
            " [1 0 1 0 1 0 1 0]\n",
            " [0 0 1 1 0 1 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow_array = bow_matrix.toarray()\n",
        "\n",
        "normalized_bow = bow_array / bow_array.sum(axis=1, keepdims=True)\n",
        "\n",
        "print(\"Normalized BoW:\\n\", normalized_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEWAy7MQyuQO",
        "outputId": "edd87b19-bc68-4c63-f31c-19815f8d0393"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized BoW:\n",
            " [[0.         0.         0.         0.33333333 0.33333333 0.33333333\n",
            "  0.         0.        ]\n",
            " [0.         0.33333333 0.         0.33333333 0.         0.33333333\n",
            "  0.         0.        ]\n",
            " [0.25       0.         0.25       0.         0.25       0.\n",
            "  0.25       0.        ]\n",
            " [0.         0.         0.2        0.2        0.         0.2\n",
            "  0.2        0.2       ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_docs)\n",
        "\n",
        "print(\"TF-IDF Vocabulary:\", tfidf_vectorizer.get_feature_names_out())\n",
        "print(\"\\nTF-IDF Matrix:\\n\", tfidf_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhRvTopey244",
        "outputId": "c447662e-3956-468b-e053-21050e47b680"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Vocabulary: ['ai' 'amazing' 'data' 'learning' 'love' 'machine' 'science' 'uses']\n",
            "\n",
            "TF-IDF Matrix:\n",
            " [[0.         0.         0.         0.53256952 0.65782931 0.53256952\n",
            "  0.         0.        ]\n",
            " [0.         0.74230628 0.         0.47380449 0.         0.47380449\n",
            "  0.         0.        ]\n",
            " [0.59081908 0.         0.46580855 0.         0.46580855 0.\n",
            "  0.46580855 0.        ]\n",
            " [0.         0.         0.45085176 0.36500336 0.         0.36500336\n",
            "  0.45085176 0.57184829]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_docs = [doc.split() for doc in processed_docs]\n",
        "print(tokenized_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1ioUmpKy9vt",
        "outputId": "e1fc778e-c97d-4ead-c1f6-66789ef39f9e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['love', 'machine', 'learning'], ['machine', 'learning', 'amazing'], ['love', 'ai', 'data', 'science'], ['data', 'science', 'uses', 'machine', 'learning']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = Word2Vec(\n",
        "    sentences=tokenized_docs,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=1,\n",
        "    workers=4\n",
        ")"
      ],
      "metadata": {
        "id": "V1bbMT9nzAcg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vector for 'machine':\\n\", w2v_model.wv['machine'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aABObQhwzENJ",
        "outputId": "c1b9d1c2-5457-4c82-dbf5-1271072a684f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for 'machine':\n",
            " [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
            "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
            " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
            " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
            "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
            "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
            "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
            " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
            " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
            "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
            "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
            " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
            "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
            " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
            "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
            " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
            "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
            "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
            "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
            " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
            " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
            "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
            "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
            "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
            "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(w2v_model.wv.most_similar('machine'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wmnmO8GzHcw",
        "outputId": "45423a18-dfb4-4ac6-f645-146e3cb22a79"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('data', 0.06797593832015991), ('uses', 0.009391162544488907), ('love', 0.0045030261389911175), ('learning', -0.010839177295565605), ('science', -0.023671656847000122), ('ai', -0.11410722136497498), ('amazing', -0.11555545777082443)]\n"
          ]
        }
      ]
    }
  ]
}